


\section{Introduction} 
When real-time tasks suspend themselves (due to blocking I/O, lock contention, \textit{etc.}), they defer a part of their execution to be processed at a later time. A consequence of such deferred execution is a potential interference penalty for lower-priority tasks~\cite{LSS:87,LSST:91,Ra:90,ABRTW:93,SLS:95,WC16-suspend-DATE,ecrts15nelissen}. This penalty, which is maximized when a task defers the completion of one job just until the release of the next job, can manifest as response-time increases and thus may lead to deadline misses.

To avoid such detrimental effects,  Rajkumar \cite{Raj:suspension1991} proposed the \emph{period enforcer} algorithm,  a technique to control (or shape) the processor demand of self-suspending tasks on uniprocessors and partitioned multiprocessors under preemptive fixed-priority scheduling. In a nutshell, the period enforcer algorithm artificially increases the length of certain suspensions whenever a task's activation pattern carries the risk of inducing undue interference in lower-priority tasks. 

The period enforcer algorithm is worth a second look for a number of reasons. First, in the words of Rajkumar, it ``forces tasks to behave like ideal periodic tasks from the scheduling point of view with no associated scheduling penalties''~\cite{Raj:suspension1991}, which is obviously highly desirable in many practical applications in which self-suspensions are inevitable (e.g., when offloading computations to co-processors such as GPUs or DSPs). Second, the later-proposed, but more widely-known \emph{released guard} algorithm~\cite{SL:96} uses a technique quite similar to period enforcement to control scheduling penalties due to release jitter in distributed systems. The period enforcer algorithm has also attracted renewed attention in recent years and has been discussed in several current works  (e.g.,~\cite{DBLP:conf/rtss/ChenL14,LNR:09,LR:10,Lak:11,LC:14,KANR:13,HY:11,CA:09,CA:10,CA:10b}), at times controversially~\cite{BA:08a}. And last but not least, the period enforcer algorithm plays a significant role in Rajkumar's seminal book on   real-time  synchronization~\cite{Raj:91}. 

In this note, we revisit the period enforcer \cite{Raj:suspension1991} to carefully re-examine and explain its underlying assumptions and limitations, and to point out potential misconceptions.  The main contributions are three observations that, to the best of our knowledge, have not been previously reported in the literature on real-time systems:
\begin{enumerate}
	\item period enforcement can be a cause of deadline misses in self-suspending task sets that are otherwise schedulable (Section~\ref{sec:unschedulable}); 
	\item to match the assumptions underlying the analysis of the period enforcer, a schedulability analysis of self-suspending tasks subject to period enforcement requires a task set  transformation that, with current techniques, is subject to exponential time complexity (Section~\ref{sec:convert}); and
	\item the period enforcer algorithm is incompatible with all existing analyses of suspension-based locking protocols, and can in fact cause ever-increasing suspension times until a deadline is missed (Section~\ref{sec:locking}).
\end{enumerate}


We briefly introduce the needed background in Section~\ref{sec:prelim}, restate our contributions more precisely in Section~\ref{sec:questions}, and then establish the three above  observations in detail in Sections \ref{sec:unschedulable}--\ref{sec:locking} before concluding in Section \ref{sec:conclusion}.

\section{Preliminaries}
\label{sec:prelim}

The period enforcer algorithm~\cite{Raj:suspension1991} applies to self-suspending tasks on uniprocessors under fixed-priority scheduling, and hence by extension also to multiprocessors under partitioned fixed-priority scheduling (where tasks are statically assigned to processors and each processor is scheduled as a uniprocessor). In this section, we review the underlying task model (Section \ref{sec:taskmodel}), introduce the period enforcer algorithm (Section \ref{sec:pe}), summarize its analysis (Section \ref{sec:classic-analysis}), and finally restate our observations in more precise terms (Section \ref{sec:questions}).

\subsection{Task Models}
\label{sec:taskmodel}

Since the analysis of the period enforcer requires reasoning about different task models and their relationships, we carefully introduce and precisely define the relevant models in this section.


\subsubsection{Periodic Tasks}

The most basic and best understood task model is the \emph{periodic task model} due to Liu and Layland~\cite{LL:73}. In this model, each task $\tau_i$ is characterized as a tuple $(C_i,T_i)$, where $C_i$ denotes an upper bound on the total execution time of any job of $\tau_i$ and $T_i$ denotes the (exact) \emph{inter-arrival time} (or \emph{period}) of $\tau_i$. Each such periodic task $\tau_i$ releases a job at time~0, and periodically every $T_i$ units thereafter. Each job must finish by the time the next arrives. Importantly, Liu and Layland assumed both that the $k$\xth job of $\tau_i$ arrives \emph{exactly} at time $(k-1)\times T_i$, and that an incomplete job is \emph{always} available for execution (i.e., jobs never block on I/O or locks).

A straightforward generalization of the periodic task model is to introduce an explicit \emph{relative deadline} parameter $D_i$. In this case, each task is represented by a three-tuple $(C_i, T_i, D_i)$, with the interpretation that every job of $\tau_i$ must finish within $D_i$ time units after its release. Task $\tau_i$ is said to have an \emph{implicit deadline}  if $D_i = T_i$, a \emph{constrained deadline} if $D_i \leq T_i$, and an \emph{arbitrary deadline} otherwise. We primarily consider implicit deadlines in this note.

\subsubsection{Sporadic Tasks}

Mok~\cite{Mo:83} introduced the \emph{sporadic task model}, in which each task $\tau_i$ is still specified by a tuple $(C_i, T_i, D_i)$. However, the sporadic task model relaxes the inter-arrival constraint $T_i$ to specify a \emph{minimum} (rather than an exact) separation between jobs. In this interpretation, the first job is not necessarily released at time~0, and the exact release times of future jobs cannot be predicted, which is an appropriate modeling assumption for event-triggered tasks.

On uniprocessors, this relaxation does not introduce additional pessimism: since any two jobs of a sporadic task $\tau_i$ are  known to be released \emph{at least} $T_i$ time units apart, the sporadic task model~\cite{Mo:83} still allows for schedulability analysis that is as accurate as Liu and Layland's analysis of periodic tasks~\cite{LL:73}. 

Mok retained the assumption that incomplete jobs are always ready for execution (i.e., no suspensions), and that jobs, once released, are \emph{immediately} available for execution. 


\subsubsection{Release Jitter}
\label{sec:jitter}

The latter assumption --- immediate availability for execution --- is inappropriate in many practical systems (especially in networked systems) if events (e.g., messages) that trigger job releases can incur non-negligible delays (e.g., network congestion). Such delays in task activation can accounted for by introducing a notion of \emph{release jitter}. To this end, each task is represented by a four-tuple $(C_i, J_i, T_i, D_i)$, where the parameter $J_i$ is a bound on the maximum time that a job remains unavailable for execution after it should have started to run. Release jitter can be incorporated in both the periodic and the sporadic task models.

In the presence of release jitter, the terms ``job arrival'' and ``job release,'' which are often used interchangeably, take on distinct meanings: a job's \emph{arrival time} denotes the point in time when it actually becomes available for execution, whereas a job's \emph{release time} is the instant that is relevant for the (minimum) inter-arrival time constraint. Any job of task $\tau_i$ thus arrives at most $J_i$ time units after it is released.

Notably, non-zero release jitter \emph{does} cause additional pessimism: in the worst case, two consecutive jobs of a task $\tau_i$ can be separated by as little as $T_i - J_i$ time units (if the earlier job incurs maximum release jitter and the successor job incurs none). As a result, a task may ``carry in'' some additional work into a given analysis interval. Taking this effect into account, Audsley et al.~\cite{ABRTW:93} developed a response-time analysis for sporadic and periodic constrained-deadline tasks subject to release jitter under preemptive fixed-priority scheduling.

However, even in the presence of release jitter, a key assumption remains that jobs do not self-suspend (e.g., wait for I/O).\footnote{Audsley et al.~\cite{ABRTW:93} do present a response-time analysis that takes into account a limited form of suspensions due to semaphores (``blocking''). However, their analysis does not apply to general self-suspensions (i.e., the kind of self-suspensions targeted by period enforcer algorithm)  and is not relevant in the context of this paper.} That is, it is assumed that, once a job has arrived, it continuously remains available for dispatching until it completes. This restriction is removed next.


\subsubsection{Self-Suspending Tasks}
\label{sec:dynamic}

When a job \emph{self-suspends}, it becomes unavailable for execution until some external event occurs (e.g., a disk I/O operation completes, a network packet arrives, a co-processor signals completion, \textit{etc.}). This has the effect of \emph{deferring} (a part of) the job's processing requirement until the time that it \emph{resumes} from its suspension, which causes massive analytical difficulties~\cite{LSS:87,LSST:91,Ra:90,ABRTW:93,SLS:95,WC16-suspend-DATE,ecrts15nelissen,Ri:04}. 

To date, the real-time literature on self-suspensions has focused on two task models: the \emph{dynamic} self-suspension model, which we discuss first,  and the \emph{segmented} (or \emph{multi-segment}) suspension model, which we discuss next in Section~\ref{sec:segmented}.  Self-suspensions can arise in both periodic and sporadic tasks (i.e, both interpretations of the $T_i$ parameter are possible); in this note we focus on sporadic tasks.

The dynamic self-suspending task model characterizes each
task $\tau_i$ as a four-tuple $(C_i,S_i,T_i,D_i)$: the parameters $C_i$, $T_i$, and $D_i$ have their usual meaning (i.e., as in the periodic and sporadic task models), and $S_i$ denotes an upper bound on the total self-suspension time of any job of $\tau_i$. The dynamic self-suspension model does not impose a bound on the maximum number of self-suspensions, nor does it make any assumptions as to where during a job's execution self-suspensions occur. That is, how often a job defers its execution, when it does so, and how much it defers varies unpredictably from job to job.

Allowing tasks to self-suspend can impose substantial scheduling penalties (an example is provided shortly in Section~\ref{sec:pe}) and greatly complicates  schedulability analysis (e.g., see~\cite{ecrts15nelissen,Ri:04,Chen2016}). In particular, release jitter and self-suspensions are not interchangeable concepts and it is not safe~\cite{Chen2016,ecrts15nelissen} to simply substitute $J_i$ with $S_i$ in Audsley et al.'s analysis~\cite{ABRTW:93}. However, under the dynamic suspension model, it is possible for jobs of self-suspending tasks to defer their entire execution requirement.

The period enforcer algorithm aims to mitigate the negative effects of self-suspensions. However, for reasons that will be explained in Section~\ref{sec:pe}, the period enforcer algorithm cannot be meaningfully combined with the dynamic suspension model. Instead, it requires a segmented suspension model, which we discuss next.


\subsubsection{Segmented Self-Suspending Tasks}
\label{sec:segmented}

The (multi-)segmented self-suspending sporadic task model extends the  four-tuple $(C_i,S_i,T_i,D_i)$ by characterizing each self-suspending task as a fixed, finite linear sequence of computation and suspension intervals. These intervals are represented as a tuple
$(S_{i}^0,C_{i}^1,S_{i}^1,C_{i}^2,S_{i}^2,...,S_{i}^{m_i-1},C_{i}^{m_i})$, which is composed of $m_i$ computation segments separated by $m_i$ suspension intervals.

The first self-suspension segment $S_i^0$, prior to the first execution segment, is equivalent to release jitter ($J_i$, Section~\ref{sec:jitter}). However, in many works on the segmented self-suspending task model, the segment $S_i^0$ assumed to be absent (i.e., $S_i^0 = 0$), such that there are only $m_i - 1$ suspension intervals (and jobs arrive jitter-free). Unless noted otherwise we adopt this convention.

We say that a segment \emph{arrives} when it becomes available for execution. The first computation segment arrives immediately when the job is released (unless $S_i^0 \neq 0$); the second computation segment (if any) arrives when the job resumes from its first self-suspension, \textit{etc.}


The advantage of the dynamic model (Section~\ref{sec:dynamic}) is that it is more flexible since it does not impose any assumptions on the task control flow. The advantage of the segmented model is that it allows for more accurate analysis. The period enforcer algorithm and its analysis~\cite{Raj:suspension1991} applies (only) to the segmented model, as explained in Section~\ref{sec:classic-analysis}. 

A note on terminology: for the sake of consistency with the recent literature on self-suspensions in real-time systems, we favor the term ``segmented self-suspending tasks'' to refer to tasks under the just-introduced model. However,  Rajkumar's original description of the period enforcer~\cite{Raj:suspension1991} refers to such tasks as  \emph{deferrable tasks}, as it predates the widespread adoption of the former term. We use both terms interchangeably in this paper.


\subsubsection{Single-Segment Self-Suspending (aka Deferrable) Tasks}
\label{sec:single-segmented}

Segmented self-suspending tasks with exactly one self-suspension interval followed by exactly one computation segment ($m_i = 1$, $S_i^0 \neq 0$) are an important special case, which we refer to as \emph{single-segment self-suspending tasks}.  This special case is central to Rajkumar's original analysis of the period enforcer~\cite{Raj:suspension1991},  as we will explain in Section~\ref{sec:classic-analysis}.
Regarding terminology, Rajkumar~\cite{Raj:suspension1991} does not use a special term for single-segment self-suspending tasks, simply referring to them as deferrable tasks. To avoid ambiguity, we instead explicitly mention the ``single-segment'' qualifier.  

Note also that single-segment self-suspending sporadic tasks, which are  ``suspended'' only prior to commencing execution, are analytically fully equivalent to sporadic task subject to release jitter (i.e., the model described in Section~\ref{sec:jitter}). We nonetheless use the term ``single-segment self-suspending sporadic task'' to remain close to Rajkumar's original description~\cite{Raj:suspension1991}, and to highlight the connection to the (multi-)segmented self-suspending task model (Section~\ref{sec:segmented}).

This concludes our review of relevant task models. Before reviewing the period enforcer and its original analysis, we briefly introduce to some essential concepts.

\subsubsection{Assumptions, Busy Periods, and Task Set Transformations}
\label{sec:misc-defs}

We focus exclusively on preemptive fixed-priority scheduling in this note, as the period enforcer is explicitly designed for this setting. For simplicity, we assume that tasks are indexed in order of decreasing priority (i.e., $\tau_1$ is the highest-priority task). 

A key concept in the period enforcer's runtime rules (discussed next) is the notion of a \emph{level-$i$ busy interval}, which is a maximal interval during which  the processor executes only segments of tasks with priority $i$ or higher.

Finally, Rajkumar's original analysis~\cite{Raj:suspension1991} of the period enforcer is rooted in the concept of a \emph{task set transformation}. In general, such a task set transformation is simply a function $f$ that maps a given task set $\tau$ to a transformed task set $\tau' = f(\tau)$ \emph{such that $\tau'$ is schedulable \textbf{only if} the original task set $\tau$ is schedulable}, too. The basic idea is that such a transformation allows a form of reduction: $\tau$ can now \emph{indirectly} be shown to be schedulable by establishing that $\tau'$ is schedulable.

Importantly, the tasks in $\tau$ and $\tau'$ do \emph{not} have to be of the same task model, nor does the number of tasks have to remain constant (i.e.,  $|\tau| \neq |\tau'|$ is possible). Specifically, the task set transformation underlying the analysis of the period enforcer maps each \emph{multi-}segmented self-suspending task $\tau_i \in \tau$  to $m_i$ \emph{single-}segmented self-suspending tasks in $\tau'$ (i.e., $|\tau'| = \sum_{\tau} m_i$ ).

With these definitions in place, we can now introduce the period enforcer. 



\subsection{The Period Enforcer Algorithm}
\label{sec:pe}

The period enforcer consists of two parts: a runtime rule that governs when a self-suspending task may be scheduled, and an (offline) analysis that may be used to assess the temporal correctness of a set of segmented self-suspending tasks (Section~\ref{sec:segmented}) subject to period enforcement. Initially, we focus on the runtime rule (i.e., the actual period enforcer algorithm) and then review the corresponding original analysis thereafter in Section~\ref{sec:classic-analysis}.  We begin with a simple example that highlights the effect that the period enforcer is designed to control.
 


\subsubsection{The Problem: Back-to-Back Execution}

The scheduling penalty associated with self-suspensions is maximized when a task defers the completion of one job just until the release of the next job.  This effect is illustrated in Figure \ref{fig:not-ok-without-period-enforcement}, which shows a case in which the self-suspension of the higher-priority task $\tau_2$ from time~1 until time~5  results in a deadline miss of the lower-priority task $\tau_3$ at time~15.

The root cause is increased interference due to the ``back-to-back'' execution effect~\cite{LSS:87,LSST:91,Ra:90,ABRTW:93,SLS:95}, where two jobs of $\tau_2$ execute in close succession (i.e, separated by less than a period) because the second job self-suspended for a (much) shorter duration than the first job. In the example shown in Figure \ref{fig:not-ok-without-period-enforcement},  $\tau_3$ misses its deadline at time~15 because of this effect as $\tau_2$'s second job resumes ``too soon'' (i.e, already at time~12 after having been suspended for only one time unit, rather than four time units like the first job of $\tau_2$). 

\begin{figure}[t]
  \centering
  \includegraphics[scale=1]{../figures/not-ok-without-period-enforcer/not-ok.pdf}
  \caption{Example uniprocessor schedule (\emph{without} period enforcement) of three tasks $\tau_1 = $, $\tau_2$, and $\tau_3$ with periods $T_1 = T_2 = T_3 = 10$. Tasks $\tau_1$ and $\tau_3$ consist of a single computation segment ($C_1^1 = C_3^1 = 3$); task $\tau_2$ consists of two computation and one suspension segment ($C_2^1 = 1$, $S_2^1 = 4$, $C_2^2 = 2$). Jobs of tasks $\tau_1$ and $\tau_3$ are released just as $\tau_2$ resumes from its self-suspension at time~$5$. Without period enforcement, task $\tau_3$ misses a deadline at time~$15$ because the second job of  task $\tau_2$ suspends only briefly (for one time unit rather than four).}
  \label{fig:not-ok-without-period-enforcement}
\end{figure}

\subsubsection{The Period Enforcement Rule}

The key idea underlying the period enforcer algorithm is to artificially delay the execution of computation segments if a job resumes ``too soon.'' To this end,  the period enforcer determines for each computation segment an \emph{eligibility time}. If a segment resumes  before its eligibility time, the execution of the segment is delayed until the eligibility time is reached.

A segment's eligibility time is determined according to the following rule. Let $ET_{i,j}^k$ denote the eligibility time of the $k$\xth computation segment of the $j$\xth job of task $\tau_i$. Further, let $a^k_{i,j}$ denote the segment's arrival time. Finally, let $\mathit{busy}(\tau_i, t')$ denote the last time that a level-$i$ busy interval began on or prior to time $t'$ (i.e., the processor executes only $\tau_i$ or higher-priority tasks throughout the interval $[\mathit{busy}(\tau_i, t'), t']$). The period enforcer algorithm defines the segment eligibility time of the $k$\xth segment as
\begin{align}\label{eq:ET-def}
	ET_{i,j}^k & = \max\left(ET_{i,j-1}^k + T_i,\ \mathit{busy}(\tau_i, a^k_{i,j})\right),
\end{align}
where $ET_{i,0}^k = -T_i$~\cite[Section 3.1]{Raj:suspension1991}. This simple and elegant rule has the desirable effect of avoiding all back-to-back execution, which can be easily observed with an example.

\subsubsection{Example: Avoiding Back-to-Back Execution}

Figure \ref{fig:ok-with-period-enforcement} illustrates how the definition of eligibility time in Equation~\ref{eq:ET-def} restores the schedulability of the task set depicted in Figure~\ref{fig:not-ok-without-period-enforcement}. Consider the eligibility times of the second segment of task $\tau_2$.

By definition,  $ET_{2,0}^2 = -T_2 = -10$. At time~5, when the second computation segment of the first job resumes ($a_{2,1}^2 = 5$), we thus have
\begin{align*}
	ET_{2,1}^2 & = \max\left(-T_2 + T_2,\ \mathit{busy}(\tau_2, a_{2,1}^2\right) ) = \max(0, 5) = 5
\end{align*}
since the arrival of $\tau_2$'s second segment (and the release of $\tau_1$) starts a new level-2 busy interval at time $a_{2,1}^2 = 5$. The second segment of $\tau_2$'s first job is hence immediately eligible to execute; however, due to the presence of a pending higher-priority job, $\tau_2$ is not actually scheduled until time~8 (just as without period enforcement as depicted in Figure \ref{fig:not-ok-without-period-enforcement}).

The second segment of the second job of $\tau_2$ arrives at time $a_{2,2}^2 = 12$. In this case, the segment is \emph{not} immediately eligible to execute since
\begin{align*}
	ET_{2,2}^2 & = \max\left(ET_{2,1}^2 + T_2,\ \mathit{busy}(\tau_2, a_{2,2}^2\right) ) = \max(5 + 10, 12) = 15.
\end{align*}
Hence, the execution of $\tau_2$'s second computation segment does not start until time $ET_{2,2}^2 = 15$, which gives $\tau_3$ sufficient time to finish before its deadline at time~$15$.


\begin{figure}[t]
  \centering
  \includegraphics[scale=1]{../figures/ok-with-period-enforcer/ok.pdf}
  \caption{Example uniprocessor schedule \emph{with} period enforcement assuming the same scenario as depicted in Figure~\ref{fig:not-ok-without-period-enforcement}. With period enforcement, task $\tau_3$ does not miss a deadline because task $\tau_2$'s second computation segment is delayed until time~15 when it no longer imposes undue interference (i.e., it is prevented from resuming ``too soon'' at time~12).}
  \label{fig:ok-with-period-enforcement}
\end{figure}

The examples in Figures \ref{fig:not-ok-without-period-enforcement} and \ref{fig:ok-with-period-enforcement} suggest an intuition for the benefits provided by period enforcement: computation segments of a self-suspending task $\tau_i$ are forced to execute at least $T_i$ time units apart (hence the name), which ensures that it causes no more interference than a regular (non-self-suspending) sporadic task.


\subsubsection{Incompatibility with the Dynamic Self-Suspension Model}
\label{sec:incompat}

Before reviewing the classic analysis based on this intuition, we briefly comment on the difficulty of combining period enforcement with the dynamic self-suspension model (Section~\ref{sec:dynamic}).

In short, the period enforcer fundamentally requires the segmented self-suspension model~(Section~\ref{sec:segmented}) to be effective because a job of a dynamic self-suspending task exhibits unpredictable execution times between its unpredictably many self-suspensions. 

A simple example can explain why the period enforcer algorithm is not compatible with the dynamic self-suspending task model. Consider a trivial system that has only one task with a total execution time $C_1=1$, a total self-suspension length $S_1=1$, and a period and relative deadline of $D_1=T_1=2$. Suppose the first job of task $\tau_1$ arrives at time~$0$, suspends itself for one time unit, and then executes for one time unit. Further suppose the second job of task $\tau_1$ arrives at time $2$, first executes for $0.5$ time units, then suspends for $1$ time unit, and finally executes for $0.5$ time units. With the period enforcer algorithm in place, the second job of task $\tau_1$ starts its execution at time $3$, at which point it will clearly miss its deadline at time $4$.

In this example, the problem is that the eligibility time of the first computation ``segment'' of the second job is determined by the self-suspension pattern of the first job, even though the first job deferred all of its execution, whereas the second job deferred only a part of its execution. Under the more restrictive segmented self-suspension model~(Section~\ref{sec:segmented}), the pattern of self-suspension and computation times is statically fixed by the model; such a mismatch is hence not possible.

Next, we revisit the original analysis of the period enforcer algorithm.


\subsection{Classic Analysis of the Period Enforcer Algorithm}
\label{sec:classic-analysis}

The central notation in Rajkumar's analysis~\cite{Raj:suspension1991} is a deferrable task, which matches our notion of segmented tasks, as already discussed in Section~\ref{sec:segmented}.  Specifically, Rajkumar states that:
\begin{quote}
With deferred execution, a task $\tau_i$ can execute its $C_i$ units of execution in discrete amounts $C_i^1, C_i^2$, $\ldots$ with suspension in between $C_i^j$ and $C_i^{j+1}$. \cite[Section 3]{Raj:suspension1991}\footnote{The notation has been altered here for the sake of consistency. } 
\end{quote}


Central to Rajkumar's analysis~\cite{Raj:suspension1991} is a task set transformation (recall Section~\ref{sec:misc-defs}) that splits each deferrable task with multiple segments (Section~\ref{sec:segmented}) into a corresponding number of single-segment deferrable tasks (Section~\ref{sec:single-segmented}).  In the words of Rajkumar~\cite[Section 3]{Raj:suspension1991}:

\begin{quote}
	 Without any loss of generality, we shall assume that a task $\tau_i$ can defer its entire execution time but not parts of it. That is, a task $\tau_i$ executes for $C_i$ units with no suspensions once it begins execution. Any task that does suspend after it executes for a while can be considered to be two or more tasks each with its own worst-case execution time. The only difference is that if a task $\tau_i$ is split into two tasks $\tau_i'$ followed by $\tau_i''$, then $\tau_i''$ has the same deadlines as $\tau_i{{'}}$. 
\end{quote}
%
In other words, the transformation can be understood as splitting each self-suspending task into a matching number of single-segment deferrable tasks (Section~\ref{sec:single-segmented}), which are equivalent to non-self-suspending sporadic tasks subject to release jitter (Section~\ref{sec:jitter}), which can be easily analyzed with classic fixed-priority response-time analysis~\cite{ABRTW:93}. To constitute an effective schedulability analysis, the transformation must ensure that, if the transformed set of single-segment deferrable tasks can be shown to be schedulable (e.g., with response-time analysis~\cite{ABRTW:93}), then the original set of multi-segment deferrable tasks is also schedulable under period enforcement.

To summarize, as illustrated in Figure \ref{fig:not-ok-without-period-enforcement},
uncontrolled deferred execution can impose  increased interference on lower-priority tasks because of the potential for ``back-to-back'' execution~\cite{LSS:87,LSST:91,Ra:90,ABRTW:93,SLS:95}. The purpose of the period enforcer algorithm is to reduce such penalties for lower-priority tasks without detrimentally affecting the schedulability of self-suspending, higher-priority tasks. The latter aspect --- no detrimental effects for self-suspending tasks --- is captured concisely by Theorem 5 in the original analysis of the period enforcer algorithm \cite{Raj:suspension1991}.
\begin{quote}
{\bf Theorem 5}: A [single-segment] deferrable task that is schedulable under its worst-case conditions is also schedulable under the period enforcer algorithm \cite{Raj:suspension1991}. 
\end{quote}
The ``worst-case conditions'' mentioned in the theorem simply correspond to the case when \textbf{(i)}~a job of a single-segment deferrable task defers its execution for the maximally allowed time $S_i^0$ (i.e., when it incurs maximal release jitter) and \textbf{(ii)} it incurs maximum higher-priority interference (i.e., when its start of execution coincides with a critical instant~\cite{LL:73}).


\subsection{Questions Answered in This Paper}
\label{sec:questions}

Theorem 5 (in \cite{Raj:suspension1991}) is a strong result, as it implies that the period enforcer does not induce any deadline misses. This seemingly enables a powerful analysis approach: if the corresponding transformed set of single-segment deferrable tasks can be shown to be schedulable  \emph{without} period enforcement under fixed-priority scheduling using \emph{any} applicable analysis (e.g.,~\cite{ABRTW:93}), then the period enforcer algorithm also yields a correct schedule. 

However, recall that, in the original analysis~\cite{Raj:suspension1991}, deferrable tasks are assumed to defer their  execution either completely or not at all (but not parts of it). It is hence important to realize that Theorem 5 in \cite{Raj:suspension1991} applies only to the transformed set of \emph{single-segment} deferrable tasks, and that it does \emph{not} apply to the \emph{original} set of multi-segmented self-suspending tasks. 

This leads to the first question: \emph{Does schedulability of the  original set of segmented self-suspending tasks (without period enforcement) imply schedulability under period enforcement?} That is, can Theorem 5 (in \cite{Raj:suspension1991}) be generalized to multi-segmented self-suspending tasks? In Section \ref{sec:unschedulable}, we answer this question in the negative.

\begin{enumerate}
	\item There exist sporadic segmented self-suspending task sets that are schedulable under fixed-priority scheduling without any enforcement, but that are infeasible under period enforcement. This shows that Theorem 5 in \cite{Raj:suspension1991} has to be  used with care --- it may be applied only in the context of the transformed single-segment deferrable task set, and not in the context of the original multi-segmented self-suspending task set.
\end{enumerate}


Therefore, to apply Theorem 5 to conclude that a set of segmented self-suspending task sets remains schedulable despite period enforcement, we first have to answer the task-set transformation question: \emph{given a set of sporadic segmented self-suspending tasks $\tau$, how do we obtain a corresponding set of single-segment deferrable tasks $\tau'$ such that $\tau'$ is schedulable  only if $\tau$ is schedulable?} That is, as discussed in Section~\ref{sec:classic-analysis} the classic analysis of the period enforcer \cite{Raj:suspension1991} presumes that it is possible to convert multi-segmented self-suspending tasks into corresponding sets of single-segment deferrable tasks, but it remains unclear in~\cite{Raj:suspension1991}  \emph{how} this central step should be accomplished. In Section \ref{sec:convert}, we make a pertinent observation.

\begin{enumerate}
\setcounter{enumi}{1}
	\item It is an open problem whether it is possible to derive a single-segment deferrable task set corresponding to a given set of  multi-segmented self-suspending tasks in polynomial time. Recent findings by Nelissen et al.~\cite{ecrts15nelissen} can be applied, but their method takes exponential time.
\end{enumerate}

Finally, we consider the use of the period enforcer in conjunction with suspension-based multiprocessor locking protocols for partitioned fixed-priority scheduling (such as the MPCP~\cite{LNR:09,Ra:90} or the FMLP~\cite{BLBA:07,BA:08}). While it is certainly tempting to apply period enforcement with the intention of avoiding the negative effects of deferred execution due to lock contention (as previously suggested elsewhere~\cite{Raj:91,Lak:11,LNR:09}), we ask: \emph{does existing blocking analysis remain safe when combined with the period enforcer algorithm?} In Section \ref{sec:locking}, we show that this is not the case.

\begin{enumerate}
\setcounter{enumi}{2}
	\item The period enforcer algorithm invalidates all existing blocking analyses for shared-memory real-time semaphore protocols as there exist non-trivial feedback cycles between the period enforcer rules and blocking durations.
\end{enumerate}



\section{Period Enforcement Can Induce Deadline Misses}
\label{sec:unschedulable}

In this section, we demonstrate with an example that there exist sets of sporadic  segmented self-suspending tasks that both \textbf{(i)} are schedulable \emph{without} period enforcement and \textbf{(ii)} are not schedulable with period enforcement.

To this end, consider a task system consisting of $2$ tasks. Let $\tau_1$ denote a sporadic task without self-suspensions and parameters $C_1 = 2$ and $T_1=D_1=10$, and let $\tau_2$ denote a self-suspending task consisting of two segments with parameters  $C_2^1 = 1$,  $S_2^1 = 6$, $C_2^2=1$, and $ T_2=D_2=11$. Suppose that we use the rate-monotonic priority assignment, i.e., $\tau_1$ has higher priority than $\tau_2$. This task set is schedulable without any enforcement since at most one computation segment of a job of $\tau_2$ can be delayed by $\tau_1$: 
\begin{itemize}
	\item if the first segment of a job of $\tau_2$ is interfered with by $\tau_1$, then the second segment resumes at most after $9$ time units after the release of the job and the response time of task $\tau_2$ is hence $10$; otherwise,
	\item  if the first segment of a job of $\tau_2$ is not interfered with by $\tau_1$, then the second segment resumes at most $7$ time units after the release of the job and hence the  response time of task $\tau_2$ is at most $10$ even if the second segment is interfered with by $\tau_1$.
\end{itemize}
Figure \ref{fig:example-original} depicts an example schedule of the task set assuming periodic job arrivals.


\begin{figure}[t]
  \centering
  \includegraphics[scale=1]{../figures/example-original/example-original.pdf}
  \caption{An illustrative example of the original self-suspending task set (without period enforcement) assuming periodic job arrivals on a uniprocessor. Task $\tau_1$ has higher priority than task $\tau_2$.}
  \label{fig:example-original}
  \end{figure}
\begin{figure}[t]
  \centering
  \includegraphics[scale=1]{../figures/example/example.pdf}
  \caption{An illustrative example demonstrating a deadline miss at time 22
    under the period enforcer algorithm. At time~19, $\tau_2$ resumes, but it remains ineligible to execute until time~20 when $\tau_1$ is released.}
\label{fig:example}  
\end{figure}


Next, let us consider the same task set under control of the period enforcer algorithm, as defined in Section \ref{sec:pe}.
Figure \ref{fig:example} shows the resulting schedule for a periodic release pattern. The first job of task $\tau_2$ (which arrives at time $a^1_{2,1} =  0$) is executed as if there is no period enforcement since the definition $ET_{2,0}^1 = ET_{2,0}^2 = -T_2$ ensures that both segments are immediately eligible. Note that the first segment of $\tau_2$'s first job is delayed due to interference from $\tau_1$. As a result, the second segment of $\tau_2$'s first job does not resume until time $a^2_{2,1} = 9$. Thus, we have
\begin{align*}
	ET_{2,1}^1 & = \max\left(-T_2 + T_2,\ \mathit{busy}(\tau_2, 0)\right) = 0  \text{ and }
\\
	ET_{2,1}^2 & = \max\left(-T_2 + T_2,\ \mathit{busy}(\tau_2, 9\right) ) = 9.
\end{align*}

In contrast to the first job, the second job of task $\tau_2$ (which is released at time $11$) is affected by period enforcement. The first segment of the second job arrives at time $a^1_{2,2} = 11$, incurs interference for one time unit during $[11, 12)$, and suspends at time $13$. The  second segment of the second job hence resumes only at time $a^2_{2,2} = 19$. Thus, we have
\begin{align*}
	ET_{2,2}^1 & = \max\left(0 + 11,\ \mathit{busy}(\tau_2, 11)\right) = 11  \text{ and }
\\
	ET_{2,2}^2 & = \max\left(9 + 11,\ \mathit{busy}(\tau_2, 19\right) ) = 20.
\end{align*}
According to the rules of the period enforcer algorithm, the processor therefore remains idle at time $19$ because the segment is not eligible to execute until time $ET_{2,2}^2 = 20$. However, at time $20$, the third job of $\tau_1$ is released. As a result, the second job of $\tau_2$ suffers from additional interference and misses its deadline at time $22$.




This example shows that there exist sporadic segmented self-suspending task sets that   \textbf{(i)} are schedulable under fixed-priority scheduling without any enforcement, but \textbf{(ii)} are not schedulable under the period enforcer algorithm.


One may consider to enrich the period enforcer with the following scheduling rule: when the processor becomes idle, a task immediately becomes eligible to execute regardless of its eligibility time. However, even with this extension, the above example remains valid by introducing one additional lower-priority task $\tau_3$ with execution time $C_3=13$ (to be executed from time $3$ to time $9$ and time $13$ to time $20$) and $T_3=D_3=100$. With task $\tau_3$, the processor is always busy from time $0$ to time $23$ and consequently $\tau_2$ still misses its deadline at time $22$.




Furthermore, the example also demonstrates that the conversion to single-segment deferrable tasks does incur a loss of generality since it introduces pessimism. In the context of the above example, if we convert the multi-segmented suspending task $\tau_2$ into two single-segment deferrable tasks, called $\tau_2^1$ and $\tau_2^2$, where task $\tau_2^1$ never defers its execution and task $\tau_2^2$ defers its execution by at most \emph{$9$} time units, the resulting single-segment deferrable task set $\{\tau_1, \tau_2^1, \tau_2^2\}$ is in fact not schedulable under the given priority assignment: if a job of $\tau_1$ coincides with the arrival of a job of $\tau_2^2$ after it has maximally deferred its execution, the job of $\tau_2^2$ has a response time of $9 + 2 + 1$ time units, which exceeds its relative deadline of 11 time units. This shows that any restriction to single-segment deferrable tasks (i.e., assuming that ``a task $\tau_i$ can defer its entire execution time but not parts of it''~\cite{Raj:suspension1991}, recall Section~\ref{sec:classic-analysis}) inherently comes with a loss of generality.

%\clearpage


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "LITES/LITES-Paper.tex"
%%% End:
